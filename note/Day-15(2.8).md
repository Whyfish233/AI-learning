# Day-15(2.8)

### 逻辑回归

​	动机与目的:**主要用于解决二分类问题**。虽然名字中带有“回归”，但它与线性回归有本质区别：逻辑回归通过概率预测对样本进行**分类**

​        分类一般有：TP(真阳),FN(假阴),FP(假阳),TN(真阴)，当然逻辑回归用不到这么大。一般**逻辑回归用在二分类问题**

​	

​	能用线性回归解决二分类问题吗：

​		从理论上来说，线性回归可以用于二分类问题，但有一些问题

​		1.**预测值范围不合理**

​		2.**模型性能受限**

​			如：真实类别是 1，预测值是 0.4，虽然平方误差较小，但实际上这是一个错误分类；而另一个样本真实类别是 0，预测值				是 0.6，同样也是错误分类

​	数据集拟合成像S型曲线。为了构造逻辑回归算法，一般用到sigmoid函数（他能将预测值映射为概率值(0,1)区间中）

![image-20250208090711356](C:\Users\为什么捉妖\AppData\Roaming\Typora\typora-user-images\image-20250208090711356.png)

​	*z是线性回归方程wixi+b

​	<img src="C:\Users\为什么捉妖\Documents\WeChat Files\wxid_ffsimc8rp8n512\FileStorage\Temp\62526e290c4b918cd778cc9ec480b37.jpg" alt="62526e290c4b918cd778cc9ec480b37" style="zoom:33%;" />







### 逻辑边界

​	1.设置阈值，高于这个阈值为1，低于这个阈值为0

​	2.决策边界，指z=wx+b=0的这一条线  

​		例一为一个二元的数据

<img src="C:\Users\为什么捉妖\Documents\WeChat Files\wxid_ffsimc8rp8n512\FileStorage\Temp\5e9b21df3172f4dbea77f13b667a730.jpg" alt="5e9b21df3172f4dbea77f13b667a730" style="zoom:33%;" />

​		例二用到了多项式回归（用多项式回归可以处理更复杂的决策边界）

<img src="C:\Users\为什么捉妖\Documents\WeChat Files\wxid_ffsimc8rp8n512\FileStorage\Temp\e8e2937d90f20be3c6d646f1c6db19e.jpg" alt="e8e2937d90f20be3c6d646f1c6db19e" style="zoom: 33%;" />

​	逻辑回归中的代价函数：

​		作用：帮助选择更好的逻辑回归函数参数

​			先理解啥是**损失函数和代价函数**

<img src="C:\Users\为什么捉妖\Documents\WeChat Files\wxid_ffsimc8rp8n512\FileStorage\Temp\532ed456a22f4e2cd5d64e0f82db488.jpg" alt="532ed456a22f4e2cd5d64e0f82db488" style="zoom: 40%;" />

<img src="C:\Users\为什么捉妖\Documents\WeChat Files\wxid_ffsimc8rp8n512\FileStorage\Temp\2c3ce0ad842888699b6ab1a86b76a08.jpg" alt="2c3ce0ad842888699b6ab1a86b76a08" style="zoom:40%;" />

​			然后逻辑回归的代价函数为：

<img src="C:\Users\为什么捉妖\Documents\WeChat Files\wxid_ffsimc8rp8n512\FileStorage\Temp\0debccb28daa925ad70da16ab98ee15.jpg" alt="0debccb28daa925ad70da16ab98ee15" style="zoom:33%;" />

​	



### 逻辑回归的梯度下降

​		和线性回归的梯度下降差不多

### 过拟合问题：

​				1.收集更多的数据，用更大的数据集完善模型

​				2.删除部分特征xi的使用

​				3.正则化（使用更小的w，即保留特征，但是使其的影响不那么大）

### 正则化：

​			定义：正则化通过在模型的损失函数中添加一个额外的项（正则化项），来对模型的复杂度进行惩罚。这样，模型在训练过				    程中不仅要考虑如何减小训练数据的误差，还要考虑如何使模型的复杂度保持在较低水平。

​			当我们不知道哪个特征重要或不重要的时候，我们删除不了部分特征，就可以采用正则化。

​			当然要是我们知道哪个不重要，也是可以直接删除这个特征的。

​			公式如下：

<img src="C:\Users\为什么捉妖\Documents\WeChat Files\wxid_ffsimc8rp8n512\FileStorage\Temp\9c9cf692cbd3627303679c179334d8d.jpg" alt="9c9cf692cbd3627303679c179334d8d" style="zoom:33%;" />

​	注：

​	*λ是一个正则常数

​	**正则化参数的选择**

1. **重要性**
   - 正则化参数（如 L1 正则化中的 *λ*）的选择对模型的性能有很大影响。如果正则化参数过大，模型可能会过于简单，导致欠拟合；如果正则化参数过小，模型可能会过于复杂，导致过拟合。

**选择方法**

- 通常使用交叉验证来选择正则化参数。例如，将数据集分为训练集、验证集和测试集。在训练集上训练模型，通过在验证集上评估模型的性能来选择合适的正则化参数，最后在测试集上评估最终模型的性能。

### 模型评估：

​			模型评估是机器学习和统计建模流程中的关键步骤，用于衡量模型的性能和泛化能力，即模型在未见过的数据上的表现。

​		      以下是关于模型评估的详细介绍：

​			他一般用来自同一个数据组的训练集、验证集、测试集判断

**一、训练集（Training Set）**

1. **定义和用途**
   - 训练集是用于训练模型的数据集。模型通过学习训练集中的样本特征和对应的标签（目标值），来调整自身的参数，从而建立起从输入特征到输出结果的映射关系。

**二、验证集（Validation Set）**

1. **定义和用途**
   - 验证集是在模型训练过程中用于评估模型性能和调整模型超参数的数据集。它不参与模型的训练，主要用于在训练过程中对模型进行初步的评估，以便选择最佳的模型结构和超参数。

**三、测试集（Test Set）**

1. **定义和用途**
   - 测试集是在模型训练和验证完成后，用于最终评估模型性能的数据集。它在整个模型开发过程中是独立的，没有参与模型的训练和超参数调整。测试集的评估结果可以反映模型在未见过的数据上的真实性能，是对模型泛化能力的最终检验。



​	问题:为啥我们不用验证集直接当测试集就OK了，这样子就只用到两个数据组了？

​		答：对模型评价的测试误差是针对未训练数据集的，测试集参与了模型选择，说明模型针对测试集进行了“训练”，所以我们的测			试集不能用来模型评价，所以得用3个数据组

​	问题：模型的介次d也是一个参数。在训练集上训练w b，在测试集上才考验泛化能力。如果有了d参数，此时的测试集就相当于是d的训练集，要增加一个额外的测试集才能验证d的泛化能力。

  2.**简单划分**

- 通常，数据集可以按照一定的比例划分为训练集、验证集和测试集。常见的比例有 60% 的数据用于训练，20% 的数据用于验证，20% 的数据用于测试；或者 70% 用于训练，15% 用于验证，15% 用于测试等。这种划分方式简单易行，但在数据量较小或者数据分布不均匀的情况下可能会导致评估结果的不准确。

问学长的问题

1.为什么代价函数J(w)~w，不能画出他的函数图像，而是用梯度下降，用电脑画这个图像不就可以知道他的J(w)最小值在哪了？

2.为啥我们不用验证集直接当测试集就OK了，这样子就只用到两个数据组了？